# M3 Specification: Phase 2 ‚Äì Velocity Extraction & Validation

**Last Updated:** 2025-12-21
**Status:** ‚úÖ IMPLEMENTED
**Related:** M3_Features.md (Parent Spec)

**Ziel:** GPS-Speed extrahieren + numerischen Validierungswert berechnen

---

## üìã KONTEXT

### Was wurde entschieden:
- GPS-Sensor liefert `speed` direkt (m/s) ‚Üí keine Haversine-Berechnung n√∂tig
- Zweispaltiges Output: `v` (float) + `v_confidence` (float 0.0-1.0)
- Confidence = numerischer Validierungswert (NICHT bool)
- KISS-Prinzip: Vertraue dem Sensor, minimale aber sinnvolle Validation

### Warum numerisch statt bool:
- Flexibilit√§t: Threshold sp√§ter setzbar (z.B. >0.7 = "valid")
- Debugging: Graduelle Abstufung sichtbar
- Zukunft: Imputation/Interpolation anhand Confidence m√∂glich

---

## üîß FUNKTION: `compute_window_velocity`

### Signatur:
```python
def compute_window_velocity(
    sensors: dict[str, pd.DataFrame], 
    features: dict[str, pd.DataFrame], 
    *, 
    window_key: str,
    sensor_name: str = "Location"
) -> dict[str, pd.DataFrame]:
```

### Input:
- `sensors["Location"]`: DataFrame mit Spalten `speed`, `speedAccuracy`
- `features[window_key]`: DataFrame mit `start_utc`, `end_utc`

### Output:
- `features[window_key]` mit **2 neuen Spalten**:
  - `v`: float (m/s) - Median-Geschwindigkeit im Fenster
  - `v_confidence`: float (0.0-1.0) - Validierungswert

---

## üßÆ CONFIDENCE-BERECHNUNG (4 Faktoren)

### **Faktor 1: speedAccuracy (Hauptfaktor, 80% Gewicht)**

**Quelle:** `speedAccuracy` aus Location-Sensor (m/s)

**Logik:**
```
Niedriger Wert = besser
Typisch: 0.5 - 3.0 m/s

Formel (linear mapping):
confidence_base = max(1.0 - (speedAccuracy / 5.0), 0.0)

Beispiele:
0.5 m/s ‚Üí 0.90
1.0 m/s ‚Üí 0.80
2.0 m/s ‚Üí 0.60
3.0 m/s ‚Üí 0.40
5.0+ m/s ‚Üí 0.00
```

**Begr√ºndung:** Sensor kennt seine eigene Unsicherheit am besten

---

### **Faktor 2: n_points (Robustheit, leichte Abwertung)**

**Quelle:** Anzahl g√ºltiger GPS-Punkte im Fenster

**Logik:**
```
1 Punkt  ‚Üí penalty = -0.15  (Einzelmessung unsicher)
2 Punkte ‚Üí penalty = -0.05  (Median schon robuster)
3+ Punkte ‚Üí penalty = 0.0   (Median sehr robust)
```

**Begr√ºndung:** Median aus mehreren Punkten filtert Ausrei√üer besser

---

### **Faktor 3: Speed-Range (Showstopper, harte Grenzen)**

**Quelle:** Berechneter Median-Speed `v`

**Logik:**
```
if v < 0.3 m/s (< 1.08 km/h):
    ‚Üí SHOWSTOPPER: confidence = 0.0
    ‚Üí Begr√ºndung: Stillstand, GPS-Noise dominiert

if v > 20.0 m/s (> 72 km/h):
    ‚Üí SHOWSTOPPER: confidence = 0.0
    ‚Üí Begr√ºndung: Unrealistisch f√ºr Fahrrad (au√üer Downhill-Profi)

if 0.3 <= v <= 20.0:
    ‚Üí Plausibel, kein Penalty
```

**Begr√ºndung:** Physikalisch unrealistische Werte sofort ausschlie√üen

---

### **Faktor 4: Stabilit√§t/Flattern (NICHT im MVP implementiert)**

**Status:** PLATZHALTER - gibt aktuell **keinen Penalty** (neutral)

**Zuk√ºnftige Logik (Post-MVP):**
```
Coefficient of Variation (CV) = std(speeds) / mean(speeds)

if CV > 1.0:  # ABSURDES Flattern (z.B. 5‚Üí50‚Üí8 m/s)
    penalty = -0.2
else:
    penalty = 0.0
```

**Warum erstmal NICHT:**
- Bei echter Beschleunigung auch hoher CV (False Positive)
- Braucht temporale Analyse (zu komplex f√ºr MVP)
- Faktor 1-3 reichen f√ºr robuste Validation

**Implementierung:** Variable einbauen, aber `penalty_stability = 0.0` hardcoden

---

## üìê AGGREGATION

### Formel:
```python
# 1. Pr√ºfe Showstopper (Faktor 3)
if v < 0.3 or v > 20.0:
    v_confidence = 0.0
    return

# 2. Berechne Base (Faktor 1)
confidence_base = max(1.0 - (mean_speedAccuracy / 5.0), 0.0)

# 3. Penalty f√ºr wenige Punkte (Faktor 2)
if n_points == 1:
    penalty_points = -0.15
elif n_points == 2:
    penalty_points = -0.05
else:
    penalty_points = 0.0

# 4. Penalty f√ºr Stabilit√§t (Faktor 4 - MVP: deaktiviert)
penalty_stability = 0.0  # TODO Post-MVP: CV-basiert

# 5. Aggregation
v_confidence = max(confidence_base + penalty_points + penalty_stability, 0.0)
v_confidence = min(v_confidence, 1.0)  # cap bei 1.0
```

**Wichtig:** Showstopper √ºberschreibt ALLES (keine Aggregation)

---

## üß™ TEST-SZENARIEN

### Szenario A: Perfekt
```
Input:
- n_points = 4
- speedAccuracy = 0.8 m/s
- speeds = [8.1, 8.0, 7.9, 8.2] m/s
- v_median = 8.05 m/s

Expected:
- v = 8.05
- confidence_base = 1.0 - (0.8/5.0) = 0.84
- penalty_points = 0.0
- penalty_stability = 0.0
- v_confidence = 0.84 ‚úÖ
```

### Szenario B: Mittelm√§√üig
```
Input:
- n_points = 2
- speedAccuracy = 2.0 m/s
- speeds = [11.5, 12.5] m/s
- v_median = 12.0 m/s

Expected:
- v = 12.0
- confidence_base = 1.0 - (2.0/5.0) = 0.6
- penalty_points = -0.05
- penalty_stability = 0.0
- v_confidence = 0.55 üü°
```

### Szenario C: Showstopper (zu schnell)
```
Input:
- n_points = 3
- speedAccuracy = 0.5 m/s (eigentlich gut!)
- speeds = [24, 26, 25] m/s
- v_median = 25.0 m/s (90 km/h)

Expected:
- v = 25.0
- SHOWSTOPPER: v > 20.0
- v_confidence = 0.0 ‚ùå
```

### Szenario D: Showstopper (Stillstand)
```
Input:
- n_points = 3
- speedAccuracy = 1.0 m/s
- speeds = [0.1, 0.2, 0.15] m/s
- v_median = 0.15 m/s

Expected:
- v = 0.15
- SHOWSTOPPER: v < 0.3
- v_confidence = 0.0 ‚ùå
```

### Szenario E: Keine GPS-Daten
```
Input:
- n_points = 0 (Fenster ohne GPS)

Expected:
- v = NaN
- v_confidence = NaN
- Warning ausgeben
```

---

## üîç IMPLEMENTIERUNGS-DETAILS

### GPS-Punkte filtern (vor Median):
```python
# Nur g√ºltige Messungen
valid_mask = (window_data["speed"] >= 0) & (window_data["speedAccuracy"] >= 0)
valid_speeds = window_data.loc[valid_mask, "speed"]
valid_accuracies = window_data.loc[valid_mask, "speedAccuracy"]

if len(valid_speeds) == 0:
    v = NaN
    v_confidence = NaN
    continue
```

### Aggregation im Fenster:
```python
v = valid_speeds.median()  # Median (robust!)
mean_speedAccuracy = valid_accuracies.mean()  # Mean Accuracy
n_points = len(valid_speeds)
```

### NaN-Handling:
```python
# Counter f√ºr Warnings
nan_count = 0

if len(valid_speeds) == 0:
    v_values.append(np.nan)
    v_confidence_values.append(np.nan)
    nan_count += 1
    continue

# Nach Loop:
if nan_count > 0:
    print(f"[Warning] compute_window_velocity: {nan_count} windows had no valid GPS data.")
```

---

## üìä OUTPUT-STRUKTUR

### Neue Spalten in `features[window_key]`:

| Spalte | Typ | Beschreibung | Wertebereich |
|--------|-----|--------------|--------------|
| `v` | float | Median-Geschwindigkeit (m/s) | 0.0 - 20.0 (oder NaN) |
| `v_confidence` | float | Validierungswert | 0.0 - 1.0 (oder NaN) |

### Beispiel-DataFrame (nach Phase 2):
```
| window_id | start_utc | end_utc | v    | v_confidence | acc_rms | ... |
|-----------|-----------|---------|------|--------------|---------|-----|
| 0         | ...       | ...     | 4.2  | 0.78         | 2.1     | ... |
| 1         | ...       | ...     | 8.5  | 0.84         | 3.8     | ... |
| 2         | ...       | ...     | 0.15 | 0.0          | 0.8     | ... | <- Showstopper
| 3         | ...       | ...     | NaN  | NaN          | 2.5     | ... | <- Keine GPS
```

---

## üéØ PHASE 3 VORBEREITUNG

### Normalisierung (sp√§ter):
```python
# In Phase 3 dann:
if v_confidence > 0.0 and v > 0.01:  # Threshold flexibel
    acc_rms_vnorm = acc_rms / (v**1.5 + 0.01)
else:
    acc_rms_vnorm = NaN
```

### Threshold-Beispiele (f√ºr sp√§tere Nutzung):
```python
# Debug/Analysis
high_quality = v_confidence >= 0.7   # vertrauensw√ºrdig
medium_quality = 0.4 <= v_confidence < 0.7  # grenzwertig
low_quality = v_confidence < 0.4     # fragw√ºrdig

# Clustering (MODEL Stage)
valid_for_normalization = v_confidence >= 0.5  # Beispiel-Threshold
```

---

## ‚ö†Ô∏è WICHTIGE HINWEISE

### Was dieser Score NICHT ist:
- ‚ùå KEINE temporale Konsistenz (Vergleich mit Nachbarfenstern)
- ‚ùå KEINE Interpolation/Imputation
- ‚ùå KEINE komplexe Physik-Modellierung
- ‚ùå KEIN Machine Learning

### Was er IST:
- ‚úÖ Sensor-basierte Qualit√§tseinsch√§tzung
- ‚úÖ Harte Grenzen f√ºr Unsinn-Werte
- ‚úÖ Transparent und nachvollziehbar
- ‚úÖ MVP-tauglich (KISS)

### Erweiterungen (Post-MVP):
- Faktor 4 aktivieren (Stabilit√§t via CV)
- Temporale Konsistenz (neue VALIDATE_VELOCITY Stage)
- Horizontal Accuracy einbeziehen
- Platform-spezifische GPS-Qualit√§t (Android vs iOS)

---

## üìù CHECKLIST F√úR IMPLEMENTIERUNG

- [x] Funktion `compute_window_velocity` erstellen
- [x] GPS-Punkte filtern (speed >= 0, speedAccuracy >= 0)
- [x] Median-Berechnung f√ºr v
- [x] Mean-Berechnung f√ºr speedAccuracy
- [x] Showstopper-Check (0.3 <= v <= 20.0)
- [x] Confidence-Base aus speedAccuracy (Faktor 1)
- [x] Penalty f√ºr n_points (Faktor 2)
- [x] Penalty f√ºr Stabilit√§t = 0.0 hardcoden (Faktor 4 Platzhalter)
- [x] Aggregation: confidence = base + penalties
- [x] NaN-Handling f√ºr Fenster ohne GPS
- [x] Warnings f√ºr NaN-Fenster ausgeben
- [x] In `run_features()` Pipeline einh√§ngen
- [x] Test mit echten Daten (Smoke-Test)
- [x] Plausibilit√§ts-Check: v-Werte realistisch? Confidence sinnvoll?

---

## üöÄ INTEGRATION IN PIPELINE

### In `src/untergrund/runners/features.py`:

```python
def run_features(ctx: "Ctx") -> "Ctx":
    w_key = select_window_key(ctx, "cluster")
    pipeline = CtxPipeline()
    
    def add_f(fn, **kwargs):
        pipeline.add(fn, source=["sensors","features"], dest="features", 
                     fn_kwargs={"window_key": w_key, **kwargs})
    
    # Phase 2: Velocity (NEU - vor Raw Features!)
    add_f(compute_window_velocity)
    
    # Phase 1: Raw Features
    add_f(acc_rms)
    add_f(acc_std)
    add_f(acc_p2p)
    add_f(zero_crossing_rate)
    add_f(acc_kurtosis)
    
    # Phase 3: Normalization (sp√§ter)
    # add_f(normalize_features_by_velocity, ...)
    
    # Taps
    pipeline.tap(row_col_nan_dur_freq, source="features")
    pipeline.tap(head_tail, source="features")
    
    return pipeline(ctx)
```

---

**Ende der Spezifikation**
