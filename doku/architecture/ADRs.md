# Architecture Decision Records (ADRs)

**Last Updated:** 2025-12-21
**Status:** âœ… Active (Append-Only)

Dieses Dokument sammelt alle architektonischen Entscheidungen chronologisch. ADRs werden nie gelÃ¶scht, nur als "Superseded" markiert.

---

# ADR 001 â€“ Keine Stage-Toggles

## Status
Accepted

## Kontext
Die Pipeline ist in feste Stages unterteilt (`INGEST â†’ SELECT â†’ PREPROCESS â†’ WINDOW â†’ FEATURES â†’ MODEL â†’ EXPORT`).  
In vielen Frameworks ist es Ã¼blich, einzelne Stages per Konfiguration ein- oder auszuschalten.  
Das kÃ¶nnte auf den ersten Blick nÃ¼tzlich wirken fÃ¼r Experimente oder Debugging.

## Entscheidung
**Alle Stages laufen immer in fester Reihenfolge.**  
- Jede Stage ist ein *Runner*, der garantiert ein `Ctx` entgegennimmt und zurÃ¼ckgibt.  
- Wenn eine Stage keine Arbeit zu erledigen hat, reicht sie den `Ctx` unverÃ¤ndert weiter (No-Op).  
- â€Stage-Togglesâ€œ Ã¼ber die Config oder CLI sind **nicht vorgesehen**.

## BegrÃ¼ndung
- **Einfachheit:** Das Orchestrator-GerÃ¼st bleibt minimal und deterministisch.  
- **Vorhersagbarkeit:** Jede AusfÃ¼hrung durchlÃ¤uft denselben Ablauf, kein Sonderfall durch deaktivierte Stages.  
- **Robustheit:** Ein Runner, der nichts zu tun hat, verursacht keinen Bruch, sondern gibt `Ctx` unverÃ¤ndert zurÃ¼ck.  
- **Erweiterbarkeit:** Neue Stages lassen sich einfÃ¼gen, ohne dass die Logik fÃ¼r â€Stage-Togglesâ€œ gepflegt werden muss.

## Konsequenzen
- **Pro:** Keine zusÃ¤tzliche KomplexitÃ¤t in Config und Orchestrator.  
- **Pro:** HÃ¶here Konsistenz und Testbarkeit.  
- **Contra:** FÃ¼r Debugging/Experimente muss eine Stage ggf. temporÃ¤r â€leerâ€œ implementiert oder lokal kommentiert werden.  
- **Mitigation:** FÃ¼r Debugging gibt es `tap`-Funktionen, um Zwischenergebnisse einzusehen, sowie Tests fÃ¼r gezielte Stages.

---

# ADR 002 â€“ Einheitliche Zeitzone: UTC

## Status
Accepted

## Kontext
Sensor-Daten enthalten Zeitstempel (z. B. Nanosekunden seit Epoche).  
In Projekten mit mehreren Datenquellen entstehen oft Probleme durch Zeitzonen, Sommer-/Winterzeit (DST) oder lokale Formate.  
Uneinheitliche Zeitzonen erschweren Preprocessing, Windowing, Export und spÃ¤tere Modellbewertung.

## Entscheidung
**Alle Zeitangaben werden intern strikt in UTC verarbeitet.**  
- Rohdaten werden beim Einlesen auf UTC normalisiert.  
- Zeitindex-Felder in DataFrames heiÃŸen konsequent `time_utc`.  
- Alle internen Operationen (Sortieren, Resampling, Windowing) erfolgen in UTC.  
- Lokale Zeitzonen (z. B. â€Europe/Berlinâ€œ) sind nur beim Export oder fÃ¼r Nutzer-Darstellung erlaubt.

## BegrÃ¼ndung
- **Eindeutigkeit:** UTC ist eine weltweite Referenz, vermeidet DST-Probleme.  
- **Reproduzierbarkeit:** Modelle und Tests liefern konsistente Ergebnisse, unabhÃ¤ngig von der lokalen Umgebung.  
- **Einfachheit:** Keine komplexe Logik in Preprocessing oder Export fÃ¼r Zeitzonen-Umrechnung.

## Konsequenzen
- **Pro:** Klare Linie, konsistenter Zeitbezug im gesamten Projekt.  
- **Pro:** Weniger Bugs durch Sommer-/Winterzeit oder lokale Abweichungen.  
- **Contra:** Nutzer erwarten oft lokale Zeiten â†’ Umrechnung beim Export/Frontend nÃ¶tig.  
- **Mitigation:** Export-Stages dÃ¼rfen zusÃ¤tzliche Spalten mit lokaler Zeit ergÃ¤nzen.

---

# ADR 003 â€“ Persistenz & Datenhaltung (Parquet + Manifest)

## Status
Proposed

## Kontext
Die Pipeline erzeugt Artefakte auf mehreren Ebenen (`sensors`, `features`, `preds`, `metrics`).  
FÃ¼r Reproduzierbarkeit und Nachvollziehbarkeit mÃ¼ssen diese konsistent gespeichert werden.  
Zur Diskussion standen: einfache Dateiausgabe (CSV/JSON), Datenbankintegration oder strukturierte Datei-Formate mit Metadaten.

## Entscheidung
- **Speicherformat:** Intern wird auf **Parquet** gesetzt (spaltenorientiert, komprimiert, schema-bewusst).  
- **Layering:** Trennung in *Bronze/Silver/Gold*:  
  - **Bronze:** normalisierte Rohsensorik (pro Sensor eine Datei).  
  - **Silver:** vorverarbeitete Sensorik (UTC-Index, resampled, bereinigt).  
  - **Gold:** Features & Predictions (modellfertig).  
- **Manifest:** Jeder Run erzeugt ein `manifest.json`, das Hashes, Config-Snapshot, Code-Versionen und Artefakt-Pfade dokumentiert.  
- **Metriken:** werden in `ctx.artifacts["metrics"]` gesammelt und als `metrics.json` persistiert.  
- **Run-ID:** wird pro AusfÃ¼hrung vergeben (z. B. Zeitstempel + Kurz-Hash); alle Artefakte landen in einem Run-Ordner.

## BegrÃ¼ndung
- **Einfachheit:** Parquet ist leichtgewichtig, direkt mit Pandas nutzbar, benÃ¶tigt keine DB-Server.  
- **Reproduzierbarkeit:** Manifest koppelt Input-Hash, Config und Output â†’ Runs sind exakt nachvollziehbar.  
- **Erweiterbarkeit:** Optional kann spÃ¤ter DuckDB oder MLflow/DVC auf den Parquet-Daten aufsetzen.  
- **Trennung:** Bronze/Silver/Gold folgt bewÃ¤hrten Data-Lake-Prinzipien, schafft klare Verantwortlichkeiten je Stage.

## Konsequenzen
- **Pro:** Reproduzierbarkeit ohne externe Infrastruktur, minimale EinstiegshÃ¼rde.  
- **Pro:** Klare Trennung von Rohdaten, Preprocessing und Features â†’ Debugging einfacher.  
- **Pro:** Erweiterbar Richtung MLflow/DVC, falls nÃ¶tig.  
- **Contra:** Kein â€always-onâ€œ-Abfrage-System (z. B. SQL-DB); Analysen laufen Ã¼ber Dateien.  
- **Mitigation:** Bei Bedarf wird eine Abfrage-Engine (DuckDB) ergÃ¤nzt, ohne die Export-Logik zu Ã¤ndern.

---

# ADR 004 â€“ Windowing als eigene Stage M2.5

## Status
Accepted (implementiert 2025-12)

## Kontext
â€Windowingâ€œ (Zeitreihen in Segmente/Fenster schneiden) liegt zwischen PREPROCESS und FEATURES.  
Bisher ist es Teil der FEATURES-Stage (KISS fÃ¼r MVP).  
FÃ¼r spÃ¤tere FlexibilitÃ¤t (A/B-Vergleiche, Caching, App-Visualisierung) kÃ¶nnte eine eigene Stage sinnvoll sein.

## Entscheidung
- **Bis M2:** Windowing bleibt in FEATURES integriert.  
- **Ab M3:** PrÃ¼fung, ob eine eigene Stage **WINDOWING** eingefÃ¼hrt wird (PREPROCESS â†’ WINDOWING â†’ FEATURES).  
- Entscheidungskriterien: Wiederverwendbarkeit, Hyperparameter-Sweeps, App-Segmente, Caching/Export von Fenstern.

## BegrÃ¼ndung
- **Pro:** Wiederverwendung, bessere Testbarkeit, Performance (einmal berechnen, mehrfach nutzen), App-UX (Segmente ohne Features darstellbar).  
- **Contra:** Mehr Contract (neue Ctx-Schublade `ctx.windows`), zusÃ¤tzliche Tests, hÃ¶here KomplexitÃ¤t.

## Konsequenzen (falls aktiviert)
- Neues Feld `ctx.windows` (Schema: `window_id`, `start_utc`, `end_utc`, `center_utc`).  
- FEATURES konsumiert Fenster aus `ctx.windows` statt selbst zu schneiden.  
- Separate Tests fÃ¼r Windowing- und Feature-Schema.  
- Optional: Export von Fenster-Artefakten.

## Migrationspfad
1. Schema `ctx.windows` definieren.  
2. FEATURES auf `ctx.windows` umstellen.  
3. Tests anpassen (Windowing/Features trennen).  
4. Optional: Export ergÃ¤nzen.  
5. Doku (README, Stage-Diagramm) aktualisieren.

## Offene Fragen
- VerknÃ¼pfung mit GPS (Center vs. Intervall)?  
- Distanz-/Geschwindigkeits-basierte Fenster statt Zeitfenster?  
- Export von Fenstern sofort nÃ¶tig oder spÃ¤ter?  

## NÃ¤chste Schritte
Dieses ADR wird zu Beginn von **M3 â€“ Feature-Berechnung** erneut geprÃ¼ft und finalisiert.  
Ergebnis (aktiviert/abgelehnt) wird hier mit Datum ergÃ¤nzt.

---

# ADR 005 â€“ Neue Ctx-Schublade `windows`

## Status
Accepted (Aktivierung ab M2.5)

## Kontext
Mit EinfÃ¼hrung der Stage **WINDOWING** (zwischen PREPROCESS und FEATURES) entsteht eine neue Datenstruktur: Fensterdefinitionen.  
Bisher war unklar, ob diese direkt in `features` oder in `artifacts` abgelegt werden.  
Das Vermischen von Fenstergrenzen und Feature-Spalten fÃ¼hrt jedoch zu semantischer UnschÃ¤rfe.

## Entscheidung
~~`Ctx` erhÃ¤lt ein zusÃ¤tzliches Feld `windows: Optional[pd.DataFrame]`.~~

**Update 2025-12:** Statt eines separaten `ctx.windows` Feldes wird das Windowing-Ergebnis direkt in `ctx.features["cluster"]` geschrieben. Dies vereinfacht die Architektur und vermeidet ein zusÃ¤tzliches Ctx-Feld. Die WINDOW-Stage schreibt ein DataFrame mit `window_id`, `start_utc`, `end_utc`, `center_utc` nach `ctx.features`, das in der FEATURES-Stage erweitert wird.

- **WINDOWING** schreibt ein DataFrame mit den Spalten:  
  - `window_id` (int, eindeutig, lÃ¼ckenlos 0..N-1)  
  - `t_start_utc`, `t_end_utc` (UTC, monotone Grenzen)  
  - optional: `duration_s`, `coverage_*`, `n_samples_*`  
- **FEATURES** konsumiert dieses DataFrame und schreibt die eigentlichen Feature-Spalten in `ctx.features`.  
- Reservierte Spalten (`window_id`, `t_start_utc`, `t_end_utc`) werden unverÃ¤ndert Ã¼bernommen.

## BegrÃ¼ndung
- **Saubere Verantwortlichkeiten:** PREPROCESS â†’ WINDOWING â†’ FEATURES ohne Ãœberschneidung.  
- **Testbarkeit:** getrennte Contracts fÃ¼r `windows` und `features`.  
- **Zukunftssicherheit:** spÃ¤ter erweiterbar (z. B. zusÃ¤tzliche Policies) ohne Umbau der Feature-Logik.  
- **Klarheit fÃ¼r Contributors:** Fenster â‰  Features â†’ weniger EinstiegshÃ¼rden.

## Konsequenzen
- Kleine SchemaÃ¤nderung am `Ctx` (neues Feld).  
- ZusÃ¤tzliche Tests fÃ¼r `ctx.windows` erforderlich.  
- Dokumentation und Diagramme (README, Stage-Ãœbersicht) mÃ¼ssen angepasst werden.  
- FÃ¼r den MVP reicht **ein einzelnes Fenster-DF**; Multi-Policy kann spÃ¤ter via Erweiterung (`dict[str, DataFrame]` oder Policy-Spalte) ergÃ¤nzt werden.

---

# ADR 006 â€“ Rollen und Schreibrechte in Pipelines

## Status
Accepted

## Kontext
In der CtxPipeline werden alle Verarbeitungsschritte Ã¼ber `.add()` oder `.tap()` registriert.  
Die Engine unterscheidet **nicht** zwischen Transformern, Validatoren oder Reportern.  
Die Begriffe dienen ausschlieÃŸlich der semantischen Einordnung und Dokumentation.

## Entscheidung
- Jeder `.add()`-Step arbeitet nach dem Vertrag `Ctx â†’ Ctx` und besitzt immer ein `source` und ein `dest`.
- Ein Step darf **ausschlieÃŸlich** in seinen definierten `dest` schreiben (â€kein Cross-Writeâ€œ).
- `.tap()`-Steps sind strikt read-only und dÃ¼rfen den `Ctx` nie verÃ¤ndern.
- Rollen sind **konventionell**, nicht technisch erzwungen:
  - **Transformer:** verÃ¤ndert Daten, schreibt z. B. in `"sensors"`.
  - **Validator:** prÃ¼ft, gibt unverÃ¤ndertes Ziel zurÃ¼ck, wirft ggf. Exception.
  - **Reporter:** liest z. B. `"sensors"` und schreibt Ergebnisse nach `"artifacts"`.
- Validatoren und Reporter erfÃ¼llen denselben technischen Vertrag wie Transformer, unterscheiden sich nur durch ihre Side-Effect-Policy.

## Konsequenzen
- Keine Sonderlogik in der Pipeline-Engine nÃ¶tig.
- Rollen-Disziplin wird Ã¼ber Namensschema, Docstrings und Tests gewÃ¤hrleistet.
- `artifacts` ist der einzige erlaubte Bereich fÃ¼r persistente Nebeninformationen (Metriken, Reports, Manifeste).

---

# ADR 007 â€“ Parametrizable Steps (`fn_kwargs` + `with_kwargs`)

## Status
Accepted

## Kontext
In der bestehenden Pipeline kÃ¶nnen Funktionen (`fn`) nur mit festen Standardwerten verwendet werden.  
FÃ¼r flexible und reproduzierbare Experimente ist es jedoch nÃ¼tzlich, beim EinhÃ¤ngen in die Pipeline Parameter zu Ã¼berschreiben, ohne dafÃ¼r separate Funktionsvarianten anzulegen.  

Bisher war das nur Ã¼ber `functools.partial` manuell mÃ¶glich â€“ jedoch uneinheitlich fÃ¼r dekorierte und undekorierte Funktionen.  
Da im Projekt nahezu alle Funktionsschritte durch `@transform_all_sensors` dekoriert sind, musste eine saubere, konsistente LÃ¶sung gefunden werden, **ohne** Pipeline- und Decorator-Schicht fest miteinander zu koppeln.

## Entscheidung
Es wird eine **zweistufige, aber einheitliche Schnittstelle** eingefÃ¼hrt:

1. **Pipeline-API (`fn_kwargs`):**  
   - `CtxPipeline.add(fn, *, source, dest=None, fn_kwargs=None)`  
   - `fn_kwargs` ist ein optionales `dict[str, Any]`, das ausschlieÃŸlich **Keyword-Parameter** an `fn` bindet.  
   - Beim HinzufÃ¼gen prÃ¼ft die Pipeline, ob alle Keys der Signatur von `fn` (oder einer kompatiblen Methode `with_kwargs`) entsprechen.  
   - UngÃ¼ltige Keys fÃ¼hren zu einer **Exception beim HinzufÃ¼gen**, nicht erst zur Laufzeit.

2. **Parametrisierbare Steps (`with_kwargs`-Protokoll):**  
   - Decorators (z. B. `@transform_all_sensors`) kÃ¶nnen optional eine Methode  
     `with_kwargs(**kw)` bereitstellen, die einen neuen, angepassten Step zurÃ¼ckgibt.  
   - Wird eine solche Methode gefunden, nutzt die Pipeline sie anstelle von `functools.partial`.  
   - So bleibt die Notation fÃ¼r alle Funktionen **identisch**:  
     ```python
     pipe.add(step, source=["sensors"], dest="sensors", fn_kwargs={"x": 5})
     ```
   - Steps ohne `with_kwargs` werden automatisch per `partial(fn, **fn_kwargs)` behandelt.

## BegrÃ¼ndung
- **Einheitlichkeit:** Ein API-Muster (`fn_kwargs`) fÃ¼r dekorierte und undekorierte Funktionen.  
- **Trennung der Schichten:** Die Pipeline kennt keine Decorator-Interna; sie prÃ¼ft nur, ob `with_kwargs` existiert.  
- **Explizit statt magisch:** Decorators bieten `with_kwargs` freiwillig an, kein versteckter Vertrag.  
- **FrÃ¼he Fehlermeldungen:** UngÃ¼ltige Keyword-Namen werden beim HinzufÃ¼gen erkannt.  
- **Reproduzierbarkeit:** Gebundene Parameter kÃ¶nnen ins Manifest/Logging aufgenommen werden.  
- **KompatibilitÃ¤t:** Bestehende Pipelines und Decorators laufen unverÃ¤ndert weiter.

## Konsequenzen
- **Pro:** Einheitliche Parametrisierung ohne Infrastrukturkopplung.  
- **Pro:** Minimalinvasiv â€“ Pipeline und Decorators bleiben unabhÃ¤ngig erweiterbar.  
- **Pro:** Klare Fehlermeldungen bei falschen Parametern, reproduzierbare Step-Labels (`func(x=5)` statt `functools.partial(...)`).  
- **Contra:** Leichter Mehraufwand bei Decorators, die Parametrisierung unterstÃ¼tzen wollen (`with_kwargs` muss einmalig implementiert werden).  
- **Mitigation:** Implementierung ist lokal in `sensors.py` mÃ¶glich und vollstÃ¤ndig testbar.

## Akzeptanzkriterien
- [x] `fn_kwargs` funktioniert fÃ¼r dekorierte **und** undekorierte Steps identisch.
- [x] Nur Keyword-Parameter erlaubt; ungÃ¼ltige Keys â†’ Exception beim HinzufÃ¼gen.
- [x] Repr zeigt verstÃ¤ndliche Step-Namen (`func(x=...)`).
- [x] `select(...).with_kwargs(...)` bleibt kompatibel und wirkt nur auf selektierte Sensoren.
- [x] Kein Zugriff der Pipeline auf `.core` oder andere Decorator-Interna.
- [x] Pipeline bleibt unverÃ¤ndert `Ctx â†’ Ctx`; alle Steps sind weiterhin pure Functions.


> **Hinweis:**  
> Das gleiche Prinzip (`with_kwargs(**kw)`) kann analog in `@inspect_all_sensors` ergÃ¤nzt werden.  
> Der Mechanismus ist identisch â€“ Broadcast Ã¼ber Sensoren, Parametrisierung Ã¼ber gebundene Keyword-Argumente â€“  
> lediglich die RÃ¼ckgabe bleibt `None` (Tap-Style). Keine Ã„nderungen an der Pipeline nÃ¶tig.

---

### ADR-008: Step Signature Policy

**Datum:** 2025-10-10  
**Status:** Accepted  
**Kontext:**
Die Transformation- und Inspektions-Decoratoren (`transform_all_sensors`, `inspect_all_sensors`) mÃ¼ssen wissen, wie sie Parameter an die zugrundeliegenden Funktionen binden.  
Um eine klare Trennung zwischen Datenfluss, Systemparametern und Konfigurationswerten zu gewÃ¤hrleisten, definieren wir verbindliche Regeln fÃ¼r Funktionssignaturen.


### Entscheidung

**Alle Step-Funktionen mÃ¼ssen folgende Struktur einhalten:**

| Kategorie | Beschreibung | Typ | Default | Beispiel |
|------------|---------------|------|----------|-----------|
| **Data Inputs** | Werte aus dem Ctx (z. B. `df`, `sensor_dfs`, `cfg`) | `POSITIONAL_OR_KEYWORD` | âŒ | `df: pd.DataFrame` |
| **Reserviert** | Systemparameter `sensor_name`, vom Decorator gesetzt | `KEYWORD_ONLY` | âŒ oder `None` (fÃ¼r Tests) | `*, sensor_name` |
| **Config/Tuning** | Ãœberschreibbare Step-Konfigurationen | `KEYWORD_ONLY` | âœ… Pflicht | `gap_len: int = 3` |

Beispiel einer korrekten Signatur:
```python
def handle_nat_in_index(
    df: pd.DataFrame, *,
    sensor_name: str,
    gap_len: int = 3
) -> pd.DataFrame:
    ...
```

---

# ADR 009 â€“ Dynamische Config-Erzeugung per Python-Prelayer

## Status
Accepted (Aktivierung ab M6)

## Kontext
Bisher wird eine statische `config.json` genutzt. Das ist reproduzierbar, aber unflexibel: keine Kommentare, keine ENV- oder CLI-Integration, keine Berechnungen.

## Entscheidung
Ein neuer **Prelayer (`.py`)** erzeugt vor jedem Run die finale JSON:
- EnthÃ¤lt eine Funktion `build_config(env, cli) -> dict`
- Kann ENV-Variablen, CLI-Parameter und Logik nutzen
- Erzeugt eine validierte, kanonische, gehashte JSON als einziges Input-Artefakt

`Ctx` speichert Pfad und Hash. Damit bleibt jede Run-Konfiguration eindeutig nachvollziehbar.

## GrÃ¼nde
- Kommentare und Logik in der Config mÃ¶glich
- ENV/CLI-Integration ohne Umwege
- Reproduzierbarkeit Ã¼ber den JSON-Hash gewÃ¤hrleistet
- JSON bleibt CI- und Tool-kompatibel

## Konsequenzen
- + Entwicklerkomfort, klare Trennung Logik/Artefakt
- + Reproduzierbarkeit durch Hash
- â€“ zusÃ¤tzlicher Build-Schritt, `.py` nur lokal erlaubt

## Beschluss
Ab **M6 â€“ Engineering & Deployment** wird jede Pipeline-Config Ã¼ber einen `.py`-Generator erstellt und als deterministische `.json` im Run-Ordner persistiert.

## Betroffene Komponenten
`Ctx`, `PipelineRunner`, `ConfigValidator`, `CLI`, `Manifest`

---

## ADR010 â€“ Einheitlicher Tap-Vertrag (dict-basiert, flatten/merge Policy)

**Datum:** 2025-11-01  
**Status:** Accepted  
**Kontext:**  
Die bisherige Tap-Implementierung Ã¼bergab je nach Quelle entweder einzelne Objekte oder verschachtelte Dict-Strukturen an Inspectoren.  
Dadurch kam es zu Inkonsistenzen (z. B. doppelt verschachtelte `{"sensors": {"acc": ...}}`) und erschwertem Debugging.

**Entscheidung:**  
Alle `tap()`-Aufrufe liefern kÃ¼nftig **immer ein flaches `dict[str, Any]`** an den Inspector.  
Die Flatten-/Merge-Policy lautet:

- `source=str`  
  - Wenn das Ctx-Attribut bereits ein `dict` ist â†’ **direkt durchreichen**.  
  - Wenn es ein Single-Objekt ist â†’ in `{source: value}` einpacken.  
- `source=list`  
  - Alle Dict-Quellen werden **gemerged**.  
  - Alle Single-Quellen werden unter ihrem Namen eingefÃ¼gt.  
  - Bei Key-Kollisionen wird der letzte Eintrag bevorzugt, eine Warnung wird ausgegeben.  
- `deepcopy=True` erzeugt eine tiefe Kopie des gesamten Dicts (Schutz vor Mutationen).  
- RÃ¼ckgabewerte des Inspectors werden **ignoriert**, bei RÃ¼ckgabe â‰  `None` erfolgt eine Warnung.

**BegrÃ¼ndung:**  
- Einheitlicher Datenvertrag fÃ¼r alle Inspectoren.  
- Kein Spezialfall-Handling mehr bei â€dict-Quellenâ€œ (z. B. `sensors`).  
- Robuster gegenÃ¼ber zukÃ¼nftigen Multi-Source-Taps.  
- Klares, reproduzierbares Verhalten bei allen Stages.

**Alternativen:**  
- Beibehaltung des bisherigen Mixed-Verhaltens â†’ fÃ¼hrte zu schwer nachvollziehbaren Fehlern.  
- Typ-spezifische Pfade fÃ¼r einzelne Objektarten â†’ unnÃ¶tig komplex.  

**Ausblick:**  
- Optionale Erweiterung auf `Mapping`-KompatibilitÃ¤t (statt reinem `dict`) mÃ¶glich, wenn kÃ¼nftig auch andere Mapping-Typen (z. B. `OrderedDict`, `UserDict`) als Quellen auftreten.  
- Aktuell bleibt die interne ReprÃ¤sentation bewusst `dict[str, Any]` fÃ¼r Einfachheit und Klarheit.


---


# ADR011 â€“ EinfÃ¼hrung eines Pipeline-Default-Mechanismus in CtxPipeline

**Datum:** 2025-11-02  
**Status:** geplant  
**Autor:** M. Neuhoff  
**Version:** Entwurf  

---

## 1) Entscheidung

In der CtxPipeline soll ein Mechanismus eingefÃ¼hrt werden, der es ermÃ¶glicht,
wiederkehrende Parameter (z. B. `source="sensors"`, `dest="features"`,
oder wiederholte `fn_kwargs={"cfg": ctx.config}`) einmalig pro Pipeline zu setzen.
Diese Werte gelten anschlieÃŸend als **Default** fÃ¼r alle folgenden `.add()`- oder `.tap()`-Aufrufe.

---

## 2) BegrÃ¼ndung

Der aktuelle Aufbau verlangt, dass in jeder Stage viele identische Parameter
immer wieder explizit angegeben werden mÃ¼ssen.
Dies ist redundant, fehleranfÃ¤llig und behindert Lesbarkeit.

Ein per-Instanz definierter Default-Mechanismus reduziert Wiederholung,
erhÃ¤lt die explizite Kontrolle pro Pipeline und verÃ¤ndert keine bisherigen VertrÃ¤ge.

---

## 3) Entwurf (Kurzform)

Neue Methoden und Verhaltensregeln in `CtxPipeline`:

```python
class CtxPipeline:
    def __init__(self):
        self._defaults = {"source": None, "dest": None, "fn_kwargs": {}}
        self._steps = []

    def set_defaults(self, *, source=None, dest=None, fn_kwargs=None):
        if source is not None:
            self._defaults["source"] = source
        if dest is not None:
            self._defaults["dest"] = dest
        if fn_kwargs:
            self._defaults["fn_kwargs"] = {**self._defaults["fn_kwargs"], **fn_kwargs}

    def add(self, fn, *, source=None, dest=None, fn_kwargs=None):
        source_final = source or self._defaults["source"]
        dest_final = dest or self._defaults["dest"]
        merged_kwargs = {**self._defaults["fn_kwargs"], **(fn_kwargs or {})}
        self._steps.append((fn, source_final, dest_final, merged_kwargs))
        return self
```

- `.set_defaults()` legt Pipeline-weite Standardwerte fest.  
- `.add()` und `.tap()` mergen diese mit per-Call-Parametern (Call > Default).  
- Bereits registrierte Schritte bleiben unverÃ¤ndert, wenn Defaults spÃ¤ter geÃ¤ndert werden.

---

## 4) Vorteile

- **KISS-Prinzip:** kein Framework-Magie, einfache Merge-Logik.
- **DRY-Prinzip:** deutlich weniger redundante Parameter in Stages.
- **Testbar:** Verhalten deterministisch und pro Instanz isoliert.
- **Kompatibel:** alle bestehenden Pipelines bleiben gÃ¼ltig.

---

## 5) Risiken und GegenmaÃŸnahmen

| Risiko | Beschreibung | GegenmaÃŸnahme |
|--------|---------------|---------------|
| Seiteneffekte durch Mutable Defaults | Ã„nderung von `fn_kwargs` in place kÃ¶nnte alle Schritte beeinflussen | immer Kopie (`{**dict}`) anlegen |
| Intransparente Defaults | Entwickler sieht Defaults evtl. nicht sofort | Pipeline-ReprÃ¤sentation zeigt *finale* Werte aller Steps |
| SpÃ¤tere Subpipelines | mÃ¶gliche doppelte Vererbung von Defaults | ADR011 nur fÃ¼r flache Pipelines, Sub-Defaults ggf. in ADR spÃ¤ter |

---

## 6) Beispielverwendung

```python
def run_preprocess(ctx: "Ctx") -> "Ctx":
    p = CtxPipeline()
    p.set_defaults(source="sensors", fn_kwargs={"cfg": ctx.config})
    p.add(time_to_index)
    p.add(nan_handling, fn_kwargs={"method": "drop"})
    p.tap(print_info)
    return p(ctx)
```

---

## 7) Entscheidungskriterien

| Kriterium | Bewertung |
|------------|------------|
| VerstÃ¤ndlichkeit | ğŸŸ¢ sehr hoch |
| Code-Wiederverwendung | ğŸŸ¢ verbessert |
| AbwÃ¤rtskompatibilitÃ¤t | ğŸŸ¢ voll |
| KomplexitÃ¤tszuwachs | ğŸŸ¡ gering |
| Wartbarkeit | ğŸŸ¢ erhÃ¶ht |

---

## 8) Status / Umsetzung

- [ ] Prototyp implementiert  
- [ ] Unit-Tests fÃ¼r Merge-Verhalten  
- [ ] Dokumentation im M6-Protokoll erstellt  
- [ ] Migration vorhandener Pipelines (`preprocess`, `features`, `window`) geplant  

---