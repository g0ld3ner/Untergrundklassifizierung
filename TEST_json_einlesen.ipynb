{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0453e59b",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import butter, filtfilt, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09458854",
   "metadata": {},
   "source": [
    "#### Daten einlsene und als Dict [Sensorname:str, DataFrame] bereitstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4502520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json zu DF\n",
    "df = pd.read_json(\"data/testdaten.json\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93910e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_Meta = df[1:].copy()\n",
    "df_non_Meta.dropna(axis=1, how=\"all\",inplace=True)\n",
    "\n",
    "df_meta = df[0:1].copy()\n",
    "df_meta.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08235d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36755e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_Meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sensor\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dict mit key=Sensor, Value=DF(Values des Sensors) -> Alle NAN-Spalten löschen -> Index zurücksetzen\n",
    "sensor_dfs = {sensor: grouped_dfs.dropna(axis=1, how=\"all\").reset_index(drop=True) for sensor, grouped_dfs in df.groupby(\"sensor\")}\n",
    "\n",
    "# Metadaten aus den Senoren nehmen\n",
    "if 'Metadata' in sensor_dfs:\n",
    "    del sensor_dfs['Metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ff463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste der Sensoren\n",
    "sensor_list = list(sensor_dfs.keys())\n",
    "sensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_dfs[\"Accelerometer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = sensor_dfs[\"Accelerometer\"]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_raw.index, df_raw[\"x\"], label=\"x\")\n",
    "plt.plot(df_raw.index, df_raw[\"y\"], label=\"y\")\n",
    "plt.plot(df_raw.index, df_raw[\"z\"], label=\"z\")\n",
    "plt.title(\"Accelerometer Rohdaten (x,y,z)\")\n",
    "plt.xlabel(\"Index (Zeit oder Sample)\")\n",
    "plt.ylabel(\"Beschleunigung\")\n",
    "plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ==> kein gravitation im Sonsorbild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sensor_dfs:\n",
    "    print(f\"{key} {sensor_dfs[key].shape}\")\n",
    "    # print(type(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe44bf4",
   "metadata": {},
   "source": [
    "#### Sensorabtastraten \"schätzen\" (AI based check):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e095174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_rates_from_elapsed(sensor_dfs, col=\"seconds_elapsed\"):\n",
    "    results = []\n",
    "    for sensor, df_s in sensor_dfs.items():\n",
    "        if col not in df_s.columns or len(df_s) < 2:\n",
    "            continue\n",
    "\n",
    "        # Zeitdifferenzen in Sekunden\n",
    "        dt = df_s[col].diff().dropna()\n",
    "        dt = dt[dt > 0]\n",
    "\n",
    "        if dt.empty:\n",
    "            continue\n",
    "\n",
    "        median_dt = dt.median()\n",
    "        mean_dt = dt.mean()\n",
    "        std_dt = dt.std(ddof=1)\n",
    "\n",
    "        results.append({\n",
    "            \"sensor\": sensor,\n",
    "            \"n_samples\": len(df_s),\n",
    "            \"median_dt_ms\": median_dt * 1000,   # s → ms\n",
    "            \"mean_dt_ms\": mean_dt * 1000,\n",
    "            \"std_dt_ms\": std_dt * 1000,\n",
    "            \"approx_rate_hz\": 1.0 / median_dt   # Hz ≈ 1 / median(s)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(\"approx_rate_hz\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df = estimate_rates_from_elapsed(sensor_dfs, col=\"seconds_elapsed\")\n",
    "rates_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe34e43",
   "metadata": {},
   "source": [
    "#### Sensoren wählen, Prüfen und Time als Index setzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_check_sensors(sensor_dfs: dict[str, pd.DataFrame], sensor_list: list[str]) -> dict[str, pd.DataFrame]:\n",
    "    selected_sensors = {sensor: data for sensor, data in sensor_dfs.items() if sensor in sensor_list}\n",
    "    for s, df in selected_sensors.items():\n",
    "        print(f\"{s:<20} {len(df):>10} Messpunkte{df.isna().sum().sum():>10} NaNs\")\n",
    "\n",
    "    return selected_sensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc129df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Das sind die ausgewählten Sensoren\n",
    "SENSOR_LIST = [\"Accelerometer\",\"Gyroscope\",\"GameOrientation\",\"Location\"]\n",
    "selected_sensors = select_and_check_sensors(sensor_dfs, SENSOR_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd349c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sensor_dfs.items():\n",
    "    if \"time\" not in v.columns:\n",
    "        print(f\"Spalte 'time' ist NICHT vorhanen in {k}\")\n",
    "    if \"seconds_elapsed\" not in v.columns:\n",
    "        print(f\"Spalte 'seconds_elapsed' ist NICHT vorhanen in {k}\")\n",
    "\n",
    "# --> alle Sonsoren enthalten beide Zeitspalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53745774",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in sensor_dfs.items():\n",
    "    if \"time\" in v.columns:\n",
    "        print(f\"-----------------------\\n{k}\\n{v[\"time\"].head(3)}\")\n",
    "\n",
    "pd.to_datetime(1.755603e18, unit=\"ns\", utc=True)\n",
    "# --> UNIX time in Nanosekunden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bf8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALLGEMEINE Funktion um spätere Funktionen auf alle Sensoren anzuwenden:\n",
    "def apply_to_all_sensors(func:Callable[[pd.DataFrame], pd.DataFrame], sensor_dfs:dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:\n",
    "    return {name: func(df) for name, df in sensor_dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_timeindex = df.copy()\n",
    "    df_timeindex.set_index(pd.to_datetime(df_timeindex[\"time\"], unit=\"ns\", utc=True),inplace=True)\n",
    "    df_timeindex.index.name = \"time_utc\"\n",
    "    df_timeindex.drop(columns=\"time\", inplace=True)\n",
    "    # später auf richtige reihenfolge der Zeitstempel, Duplikate und Lücken prüfen\n",
    "    return df_timeindex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee49d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datetime Index für alle Sensor DFs\n",
    "selected_sensors = apply_to_all_sensors(time_to_index,selected_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors[\"Accelerometer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0e78d",
   "metadata": {},
   "source": [
    "#### Sensorabtastraten \"schätzen\",  detailierter (AI based check):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2912bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_benchmark(df: pd.DataFrame, high_gap_factor: float = 3.0) -> dict:\n",
    "    \"\"\"\n",
    "    MVP: Qualität der Zeitachse eines einzelnen Sensor-DFs beurteilen.\n",
    "    Erwartet: DatetimeIndex (UTC, ns). Keine Änderungen am Signal.\n",
    "    \n",
    "    Kennzahlen:\n",
    "      - rows, duration_s\n",
    "      - n_deltas (Anzahl Abstände), n_nonpos (Δt <= 0)\n",
    "      - median_dt_ns, mean_dt_ns, std_dt_ns, p95_dt_ns, max_dt_ns\n",
    "      - approx_hz (1e9 / median_dt_ns)\n",
    "      - jitter_cv = std_dt_ns / median_dt_ns\n",
    "      - large_gap_count (Δt > high_gap_factor * median_dt_ns)\n",
    "      - large_gap_max_ns (größte „große Lücke“)\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"rows\": len(df),\n",
    "        \"duration_s\": np.nan,\n",
    "        \"n_deltas\": 0,\n",
    "        \"n_nonpos\": 0,\n",
    "        \"median_dt_ns\": np.nan,\n",
    "        \"mean_dt_ns\": np.nan,\n",
    "        \"std_dt_ns\": np.nan,\n",
    "        \"p95_dt_ns\": np.nan,\n",
    "        \"max_dt_ns\": np.nan,\n",
    "        \"approx_hz\": np.nan,\n",
    "        \"jitter_cv\": np.nan,\n",
    "        \"large_gap_factor\": high_gap_factor,\n",
    "        \"large_gap_count\": 0,\n",
    "        \"large_gap_max_ns\": np.nan,\n",
    "    }\n",
    "    if len(df) < 2:\n",
    "        return out\n",
    "\n",
    "    # Gesamtdauer\n",
    "    out[\"duration_s\"] = (df.index[-1] - df.index[0]).total_seconds()\n",
    "\n",
    "    # Δt in ns (Index ist datetime64[ns])\n",
    "    ts_ns = df.index.view(\"int64\")\n",
    "    dt = np.diff(ts_ns)\n",
    "    out[\"n_deltas\"] = int(dt.size)\n",
    "    if dt.size == 0:\n",
    "        return out\n",
    "\n",
    "    # nicht-positive Deltas nur für die Statistik zählen, für Kennzahlen ignorieren\n",
    "    out[\"n_nonpos\"] = int((dt <= 0).sum())\n",
    "    dt_pos = dt[dt > 0]\n",
    "    if dt_pos.size == 0:\n",
    "        return out\n",
    "\n",
    "    # robuste „typische Schrittweite“\n",
    "    median_dt_ns = float(np.median(dt_pos))\n",
    "    mean_dt_ns   = float(np.mean(dt_pos))\n",
    "    std_dt_ns    = float(np.std(dt_pos, ddof=1)) if dt_pos.size > 1 else 0.0\n",
    "    p95_dt_ns    = float(np.quantile(dt_pos, 0.95))\n",
    "    max_dt_ns    = float(np.max(dt_pos))\n",
    "\n",
    "    out[\"median_dt_ns\"] = median_dt_ns\n",
    "    out[\"mean_dt_ns\"]   = mean_dt_ns\n",
    "    out[\"std_dt_ns\"]    = std_dt_ns\n",
    "    out[\"p95_dt_ns\"]    = p95_dt_ns\n",
    "    out[\"max_dt_ns\"]    = max_dt_ns\n",
    "    out[\"approx_hz\"]    = (1e9 / median_dt_ns) if median_dt_ns > 0 else np.nan\n",
    "    out[\"jitter_cv\"]    = (std_dt_ns / median_dt_ns) if median_dt_ns > 0 else np.nan\n",
    "\n",
    "    # große Lücken gegenüber „typischem“ Schritt\n",
    "    thr = high_gap_factor * median_dt_ns\n",
    "    large = dt_pos[dt_pos > thr]\n",
    "    out[\"large_gap_count\"]  = int(large.size)\n",
    "    out[\"large_gap_max_ns\"] = float(np.max(large)) if large.size else np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def timing_benchmark_all(sensors: dict[str, pd.DataFrame], high_gap_factor: float = 3.0) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for name, df in sensors.items():\n",
    "        m = timing_benchmark(df, high_gap_factor=high_gap_factor)\n",
    "        m[\"sensor\"] = name\n",
    "        rows.append(m)\n",
    "    cols = [\"sensor\",\"rows\",\"duration_s\",\"n_deltas\",\"n_nonpos\",\n",
    "            \"median_dt_ns\",\"mean_dt_ns\",\"std_dt_ns\",\"p95_dt_ns\",\"max_dt_ns\",\n",
    "            \"approx_hz\",\"jitter_cv\",\"large_gap_factor\",\"large_gap_count\",\"large_gap_max_ns\"]\n",
    "    return pd.DataFrame(rows)[cols].sort_values(\"sensor\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = timing_benchmark_all(selected_sensors, high_gap_factor=3.0)\n",
    "bench  # im Notebook als Tabelle anzeigen lassen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7e223",
   "metadata": {},
   "source": [
    "#### Auf feste Zeiten resamplen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = \"5ms\" #200hz\n",
    "\n",
    "def resample_imu_sensors(df: pd.DataFrame, step: str = STEPS) -> pd.DataFrame:\n",
    "    #out = df.resample(step).mean(numeric_only=True)\n",
    "    out = df.resample(step, origin=\"epoch\", label=\"left\", closed=\"left\").mean(numeric_only=True)\n",
    "    out = out.interpolate(method=\"time\", limit_direction=\"both\")\n",
    "    return out\n",
    "\n",
    "def resample_location(df: pd.DataFrame, step: str = STEPS) -> pd.DataFrame:\n",
    "    # resample speziell für die langsame abtastrate der Location\n",
    "    out = df.resample(step, origin=\"epoch\", label=\"left\", closed=\"left\").ffill()\n",
    "    return out\n",
    "\n",
    "def resample_selected_sensors(selected: dict[str, pd.DataFrame], step: str = STEPS) -> dict[str, pd.DataFrame]:\n",
    "    out: dict[str, pd.DataFrame] = {}\n",
    "    for name, df in selected.items():\n",
    "        if name == \"Location\":\n",
    "            out[name] = resample_location(df, step)\n",
    "        else:\n",
    "            out[name] = resample_imu_sensors(df, step)\n",
    "\n",
    "    # Quick-Sanity: haben alle denselben Index?\n",
    "    if not out:\n",
    "        return out\n",
    "    idx0 = next(iter(out.values())).index\n",
    "    for n, d in out.items():\n",
    "        if not d.index.equals(idx0):\n",
    "            # Für MVP nicht hart abbrechen, nur sichtbar machen:\n",
    "            print(f\"⚠️ Index von {n} weicht ab (Länge={len(d)}, Start={d.index[0]}, Ende={d.index[-1]})\")\n",
    "            \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18451288",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_sensors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_sensors = resample_selected_sensors(selected_sensors,STEPS)\n",
    "#### NEXT:\n",
    "#### Alle Senoren auf die länge vom ersten bis letzen GPS-fix aus \"Locations\" schneiden...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0513a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_sensors[\"Location\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f2ee3",
   "metadata": {},
   "source": [
    "#### Alle Sonsoren auf gemeinsamen (Location) Index slicen:\n",
    "Für den MVP werden die Start und Endzeitpunkte auf den ersten und letzten GPS-Fix gesetzt, später muss das etwas intelligenter Implementiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_window_no_nans(location_df: pd.DataFrame) -> tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"\n",
    "    Gibt (t0, t1) zurück:\n",
    "      t0 = erster Index, dessen gesamte Zeile keine NaNs enthält\n",
    "      t1 = letzter Index, dessen gesamte Zeile keine NaNs enthält\n",
    "\n",
    "    Erwartet: Location hat bereits DatetimeIndex (z. B. nach time_to_index + Resampling).\n",
    "\n",
    "    Hinweise:\n",
    "    - MVP: keine Rücksicht auf Accuracy-Werte (horizontal/verticalAccuracy, etc.).\n",
    "      Ein strengerer Fix könnte später z.B. eine Mindestgenauigkeit erfordern.\n",
    "    - Gibt zusätzlich Info aus, wie viele Sekunden vorne/hinten abgeschnitten werden.\n",
    "    \"\"\"\n",
    "    if len(location_df) == 0:\n",
    "        raise ValueError(\"Location ist leer.\")\n",
    "\n",
    "    # Falls eine keine Zeilen ohne NaNs geben sollte\n",
    "    valid = location_df.notna().all(axis=1)\n",
    "    if not valid.any():\n",
    "        raise ValueError(\"Keine vollständig NaN-freie Zeile in Location gefunden.\")\n",
    "\n",
    "    t0 = valid.idxmax()           # erster True-Index\n",
    "    t1 = valid[::-1].idxmax()     # letzter True-Index\n",
    "\n",
    "    # Debug-Infos: abgeschnittene Zeiträume\n",
    "    total = (location_df.index[-1] - location_df.index[0]).total_seconds()\n",
    "    cut_front = (t0 - location_df.index[0]).total_seconds()\n",
    "    cut_back = (location_df.index[-1] - t1).total_seconds()\n",
    "    print(f\"⏱️ GPS-Window: Gesamt {total:.2f} s, vorne abgeschnitten {cut_front:.2f} s, hinten {cut_back:.2f} s\")\n",
    "\n",
    "    #TypeCheck t0, t1\n",
    "    print(\"\\n\")\n",
    "    print(\"Type of returned values:\")\n",
    "    print(type(t0))\n",
    "    print(type(t1))\n",
    "    \n",
    "\n",
    "    return t0, t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7830ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = location_window_no_nans(resampled_sensors[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e19003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_all_sensors(sensors:dict[str, pd.DataFrame], start:pd.Timestamp, end:pd.Timestamp) -> dict[str, pd.DataFrame]:\n",
    "    sliced_sensors = {name : df.loc[start:end] for name, df in sensors.items()}\n",
    "    return sliced_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_sensors = slice_all_sensors(resampled_sensors, start, end)\n",
    "\n",
    "for k, v in sliced_sensors.items():\n",
    "    print(f\"{k:<16} {len(v):>6} rows  Start={v.index[0]}  Ende={v.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f547c",
   "metadata": {},
   "source": [
    "### Pre-Preprocessing HP-Filter für x,y,z der Sensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_highpass_axes(df: pd.DataFrame, fs=200.0, fc=0.5, order=4, suffix=\"_hp\"):\n",
    "    \"\"\"\n",
    "    Minimalversion: Butterworth-Highpass pro Achse (x,y,z).\n",
    "    Hängt neue Spalten x_hp, y_hp, z_hp an.\n",
    "    \"\"\"\n",
    "    nyq = fs / 2.0\n",
    "    Wn = fc / nyq\n",
    "    b, a = butter(order, Wn, btype=\"highpass\")\n",
    "\n",
    "    out = df.copy()\n",
    "    for ax in [\"x\", \"y\", \"z\"]:\n",
    "        if ax in out.columns:\n",
    "            # TODO: später NaN-Handling einbauen\n",
    "            # TODO: später prüfen ob Serie lang genug ist\n",
    "            s = out[ax].astype(float)\n",
    "            s_hp = filtfilt(b, a, s.to_numpy())\n",
    "            out[ax + suffix] = s_hp\n",
    "        else:\n",
    "            out[ax + suffix] = np.nan  # TODO: später schöner handeln\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2711271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_sensors[\"Accelerometer\"] = apply_highpass_axes(sliced_sensors[\"Accelerometer\"])\n",
    "sliced_sensors[\"Gyroscope\"] = apply_highpass_axes(sliced_sensors[\"Gyroscope\"])\n",
    "sliced_sensors[\"GameOrientation\"] = apply_highpass_axes(sliced_sensors[\"GameOrientation\"])\n",
    "sliced_sensors[\"Location\"] = apply_highpass_axes(sliced_sensors[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_sensors[\"Accelerometer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb02685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisierung der Filterwirkung\n",
    "\n",
    "# Zugriff direkt auf den Accelerometer-DF im Dict\n",
    "df = sliced_sensors[\"Accelerometer\"]\n",
    "\n",
    "# wieviel Zeit anzeigen?\n",
    "PLOT_SECONDS = 20\n",
    "t0 = df.index[0]\n",
    "t1 = t0 + pd.Timedelta(seconds=PLOT_SECONDS)\n",
    "view = df.loc[t0:t1]\n",
    "\n",
    "print(f\"Zeige von {t0} bis {t1} | {len(view)} Punkte (~{PLOT_SECONDS} s)\")\n",
    "\n",
    "for ax in [\"x\",\"y\",\"z\"]:\n",
    "    hp_col = f\"{ax}_hp\"\n",
    "    if ax not in view.columns or hp_col not in view.columns:\n",
    "        print(f\"Überspringe {ax}: Spalte fehlt ({ax} / {hp_col})\")\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.plot(view.index, view[ax],     label=f\"{ax} (raw)\")\n",
    "    plt.plot(view.index, view[hp_col], label=f\"{hp_col} (high-pass)\")\n",
    "    plt.title(f\"Accelerometer – {ax} vs. {hp_col}\")\n",
    "    plt.xlabel(\"Zeit\")\n",
    "    plt.ylabel(\"Beschleunigung [m/s²]\")\n",
    "    plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sliced_sensors[\"Accelerometer\"]\n",
    "print(\"Mittelwerte (ruhig liegend):\")\n",
    "print(df[[\"x\",\"y\",\"z\"]].mean())\n",
    "print(\"Magnitude (ruhig liegend):\", np.sqrt((df[[\"x\",\"y\",\"z\"]]**2).sum(axis=1)).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a77c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mittelwerte (hochpassgefiltert):\")\n",
    "print(df[[\"x_hp\",\"y_hp\",\"z_hp\"]].mean())\n",
    "print(\"Magnitude (hochpassgefiltert):\", np.sqrt((df[[\"x_hp\",\"y_hp\",\"z_hp\"]]**2).sum(axis=1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329012a",
   "metadata": {},
   "source": [
    "### Features für die jeweiligen Sensoren erstellen:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edecb47",
   "metadata": {},
   "source": [
    "#### Dataframe mit variablen Zeitfenstern für die Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c72c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Globale Parameter:\n",
    "\n",
    "WINDOW_LEN = 2.0 #Intervalllänge in Sekunden\n",
    "WINDOW_STEP = 1.0 #Steps je Intervall in Sekunden\n",
    "\n",
    "L = pd.to_timedelta(WINDOW_LEN,  unit=\"s\")\n",
    "S = pd.to_timedelta(WINDOW_STEP, unit=\"s\")\n",
    "# z.b. window_len = 2 und window_steps = 1 --> jede Sekunde ein 2 Sekunden Fenster =  50% Überlappung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Referenzindex der Sensoren\n",
    "ref_df = next(iter(sliced_sensors.values())) # Index des ersten Sonsors, da alle Sensoren auf den gleichen Index gesliced sind.\n",
    "idx = ref_df.index\n",
    "print(\"Referenzindex:\", type(idx), \"Länge:\", len(idx))\n",
    "print(\"Start:\", idx[0], \"Ende:\", idx[-1])\n",
    "\n",
    "start = idx[0]\n",
    "end   = idx[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf773f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Anzahl Fenster: n = floor((T - L)/S) + 1  (nur vollständige Fenster) ---\n",
    "T = end - start\n",
    "n = int(np.floor((T - L) / S)) + 1 if T >= L else 0\n",
    "\n",
    "# --- Fensterstarts und -mitten (simpel: Mitte = Start + L/2) ---\n",
    "if n > 0:\n",
    "    t_start = start + np.arange(n) * S\n",
    "    t_mid   = t_start + L/2\n",
    "    windows = pd.DataFrame({\"t_start\": t_start, \"t_mid\": t_mid})\n",
    "else:\n",
    "    windows = pd.DataFrame({\"t_start\": pd.to_datetime([]), \"t_mid\": pd.to_datetime([])})\n",
    "\n",
    "print(f\"Fenster gebaut: {len(windows)} | Start={start} | Ende={end} | L={L} | S={S}\")\n",
    "\n",
    "windows # <---- Zeitfenster als Index für die Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9d88f",
   "metadata": {},
   "source": [
    "#### Accelerometer --> Magnitude RMS (GRAVITATION IST SCHON RAUS --> NOCHMAL ÜBERARBEITEN!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bef41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_name = \"Accelerometer\"\n",
    "accel_df = sliced_sensors[sensor_name]\n",
    "\n",
    "rows = []\n",
    "for t0, tmid in zip(windows[\"t_start\"], windows[\"t_mid\"]):\n",
    "    # Slice des Sensor-DF für dieses Fenster (rechts offen)\n",
    "    mask  = (accel_df.index >= t0) & (accel_df.index < t0 + L)\n",
    "    chunk = accel_df.loc[mask]\n",
    "    if chunk.empty:\n",
    "        raise RuntimeError(f\"Leeres Fenster bei t0={t0} (Index {accel_df.index[0]} ... {accel_df.index[-1]})\")\n",
    "    # ohne Gravitation\n",
    "    mag2 = chunk[\"x\"]**2 + chunk[\"y\"]**2 + chunk[\"z\"]**2\n",
    "    mag_rms = float(np.sqrt(np.mean(mag2)))\n",
    "    # mit HP-Filter\n",
    "    mag2_hp = chunk[\"x_hp\"]**2 + chunk[\"y_hp\"]**2 + chunk[\"z_hp\"]**2\n",
    "    mag_rms_hp = float(np.sqrt(np.mean(mag2_hp)))\n",
    "    \n",
    "    rows.append({\"t_start\": t0, \"t_mid\": tmid, \"mag_rms\": mag_rms, \"mag_rms_hp\": mag_rms_hp})\n",
    "\n",
    "accelerometer_features = pd.DataFrame(rows).set_index(\"t_start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerometer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: mag_rms vs mag_rms_hp\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(accelerometer_features[\"t_mid\"], accelerometer_features[\"mag_rms\"], \n",
    "         label=\"mag_rms (alle Frequenzen)\", color=\"blue\", linewidth=1.5)\n",
    "plt.plot(accelerometer_features[\"t_mid\"], accelerometer_features[\"mag_rms_hp\"], \n",
    "         label=\"mag_rms_hp (langsame Bewegungen entfernt)\", color=\"red\", linewidth=1.5)\n",
    "plt.title(\"Accelerometer Magnitude RMS Vergleich\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Magnitude RMS [m/s²]\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(accelerometer_features[\"t_mid\"], accelerometer_features[\"mag_rms\"] - accelerometer_features[\"mag_rms_hp\"], \n",
    "         label=\"Differenz (entfernte langsame Bewegungen)\", color=\"green\", linewidth=1.5)\n",
    "plt.title(\"Durch HP-Filter entfernte langsame Bewegungskomponenten\")\n",
    "plt.xlabel(\"Zeit\")\n",
    "plt.ylabel(\"Differenz [m/s²]\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiken ausgeben\n",
    "print(f\"mag_rms (alle Frequenzen):        Mean={accelerometer_features['mag_rms'].mean():.4f}, Std={accelerometer_features['mag_rms'].std():.4f}\")\n",
    "print(f\"mag_rms_hp (HP-gefiltert):        Mean={accelerometer_features['mag_rms_hp'].mean():.4f}, Std={accelerometer_features['mag_rms_hp'].std():.4f}\")\n",
    "print(f\"Entfernte langsame Komponenten:   Mean={(accelerometer_features['mag_rms'] - accelerometer_features['mag_rms_hp']).mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (untergrund)",
   "language": "python",
   "name": "untergrund"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
